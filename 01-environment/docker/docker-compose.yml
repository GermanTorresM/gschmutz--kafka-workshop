#
# Docker Compose with the following services:
#  Zookeeper
#  Kafka Broker 1-3
#  Schema Registry
#  Kafka Connect 1 - 2
#  Kafka Rest Proxy
#  KSQL server
#  Schema Registry UI
#  Kafka Connect UI
#  Kafka Manager
#  Zoonavigator
#  Kafdrop
#  Streamsets
#  Apache NiFi
#

version: '2'
services:
  zookeeper-1:
    image: confluentinc/cp-zookeeper:5.3.1
    hostname: zookeeper-1
    container_name: zookeeper-1
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: always

  broker-1:
    image: confluentinc/cp-kafka:5.3.1
    hostname: broker-1
    container_name: broker-1
    depends_on:
      - zookeeper-1
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_BROKER_RACK: 'r1'
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-1:2181'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://${PUBLIC_IP}:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_JMX_PORT: 9994
    restart: always

  broker-2:
    image: confluentinc/cp-kafka:5.3.1
    hostname: broker-2
    container_name: broker-2
    depends_on:
      - zookeeper-1
    ports:
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_BROKER_RACK: 'r1'
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-1:2181'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://${PUBLIC_IP}:9093'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_JMX_PORT: 9993
    restart: always

  broker-3:
    image: confluentinc/cp-kafka:5.3.1
    hostname: broker-3
    container_name: broker-3
    depends_on:
      - zookeeper-1
    ports:
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_BROKER_RACK: 'r1'
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper-1:2181'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://${PUBLIC_IP}:9094'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_JMX_PORT: 9992
    restart: always
      
  schema-registry-1:
    image: confluentinc/cp-schema-registry:5.3.1
    hostname: schema-registry-1
    container_name: schema-registry-1
    depends_on:
      - zookeeper-1
      - broker-1
    ports:
      - "28030:8081"
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry-1
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: 'zookeeper-1:2181'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS: 'GET,POST,PUT,OPTIONS'
    restart: always
      
  connect-1:
    image: confluentinc/cp-kafka-connect:5.3.1
    hostname: connect-1
    container_name: connect-1
    depends_on:
      - zookeeper-1
      - broker-1
      - schema-registry-1
    ports:
      - "28013:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker-1:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect-1
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry-1:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry-1:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: 'zookeeper-1:2181'
      CONNECT_PLUGIN_PATH: "/usr/share/java,/etc/kafka-connect/custom-plugins"
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-4.0.0.jar
      AWS_ACCESS_KEY_ID: V42FCGRVMK24JJ8DHUYG
      AWS_SECRET_ACCESS_KEY: bKhWxVF3kQoLY9kFmt91l+tDrEoZjqnWXzY9Eza
    volumes:
      - ./kafka-connect:/etc/kafka-connect/custom-plugins
    restart: always

  connect-2:
    image: confluentinc/cp-kafka-connect:5.3.1
    hostname: connect-2
    container_name: connect-2
    depends_on:
      - zookeeper-1
      - broker-1
      - schema-registry-1
    ports:
      - "28014:8084"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'broker-1:9092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect-2
      CONNECT_REST_PORT: 8084
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 3
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry-1:8081'
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry-1:8081'
      CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_ZOOKEEPER_CONNECT: 'zookeeper-1:2181'
      CONNECT_PLUGIN_PATH: "/usr/share/java,/etc/kafka-connect/custom-plugins"
      CONNECT_LOG4J_ROOT_LOGLEVEL: INFO
      CLASSPATH: /usr/share/java/monitoring-interceptors/monitoring-interceptors-4.0.0.jar
      AWS_ACCESS_KEY_ID: V42FCGRVMK24JJ8DHUYG
      AWS_SECRET_ACCESS_KEY: bKhWxVF3kQoLY9kFmt91l+tDrEoZjqnWXzY9Eza
    volumes:
      - ./kafka-connect:/etc/kafka-connect/custom-plugins
    restart: always

  ksqldb-server-1:
    image: confluentinc/ksqldb-server:0.6.0
#    image: confluentinc/cp-ksql-server:5.3.1
    hostname: ksqldb-server-1
    container_name: ksqldb-server-1
    ports:
      - "28031:8088"
    depends_on:
      - broker-1
      - schema-registry-1
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql-server"
      KSQL_APPLICATION_ID: "geo-ksql"
      KSQL_KSQL_EXTENSION_DIR: "/etc/ksql-server/ext"
      KSQL_BOOTSTRAP_SERVERS: "broker-1:9092,broker-2:9093"
      KSQL_HOST_NAME: ksqldb-server-1
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry-1:8081"
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_CONNECT_URL: http://connect-1:8083,http://connect-2:8084
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
    volumes:
      - $PWD/ksql:/etc/ksql-server/ext      
    restart: always

  ksqldb-server-2:
    image: confluentinc/ksqldb-server:0.6.0
#    image: confluentinc/cp-ksql-server:5.3.1
    hostname: ksqldb-server-2
    container_name: ksqldb-server-2
    ports:
      - "28032:8088"
    depends_on:
      - broker-1
      - schema-registry-1
    environment:
      KSQL_CONFIG_DIR: "/etc/ksql-server"
      KSQL_APPLICATION_ID: "geo-ksql"
      KSQL_KSQL_EXTENSION_DIR: "/etc/ksql-server/ext"
      KSQL_BOOTSTRAP_SERVERS: "broker-1:9092,broker-2:9093"
      KSQL_HOST_NAME: ksqldb-server-2
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_KSQL_SCHEMA_REGISTRY_URL: "http://schema-registry-1:8081"
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_CONNECT_URL: http://connect-1:8083,http://connect-2:8084
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
    volumes:
      - $PWD/ksql:/etc/ksql-server/ext      
    restart: always

  ksqldb-cli:
#    image: confluentinc/ksqldb-cli:0.6.0
    image: confluentinc/cp-ksql-cli:5.3.1
    container_name: ksqldb-cli
    depends_on:
      - ksqldb-server-1
      - ksqldb-server-2
    entrypoint: /bin/sh
    tty: true

  kafka-rest-1:
    image: confluentinc/cp-kafka-rest:5.3.1
    hostname: rest-proxy
    container_name: kafka-rest-1
    depends_on:
      - broker-1
      - schema-registry-1
    ports:
      - "28012:8086"
    environment:
      KAFKA_REST_ZOOKEEPER_CONNECT: '${DOCKER_HOST_IP}:2181'
      KAFKA_REST_LISTENERS: 'http://0.0.0.0:8086'
      KAFKA_REST_SCHEMA_REGISTRY_URL: 'http://schema-registry-1:8081'
      KAFKA_REST_HOST_NAME: 'rest-proxy'
    restart: always

  schema-registry-ui:
    image: landoop/schema-registry-ui
    hostname: schema-registry-ui
    container_name: schema-registry-ui
    depends_on:
      - broker-1
      - schema-registry-1
    ports:
      - "28039:8000"
    environment:
      SCHEMAREGISTRY_URL: 'http://${PUBLIC_IP}:28030'
    restart: always

  kafka-connect-ui:
    image: landoop/kafka-connect-ui
    hostname: kafka-connect-ui
    container_name: kafka-connect-ui
    ports:
      - "28038:8000"
    environment:
      CONNECT_URL: "http://${PUBLIC_IP}:8083/,http://${PUBLIC_IP}:8084/"
      PROXY: "true"
    depends_on:
      - connect-1
    restart: always

  kafka-manager:
    image: trivadisbds/kafka-manager
    hostname: kafka-manager
    container_name: kafka-manager
    depends_on:
      - zookeeper-1
      - broker-1
      - broker-2
      - broker-3
    ports:
      - "28044:9000"
    environment:
      ZK_HOSTS: 'zookeeper-1:2181'
      APPLICATION_SECRET: 'letmein'
    restart: always

  kafkahq:
    image: tchiotludo/kafkahq
    container_name: kafkahq
    ports:
      - 28042:8080
    environment:
      KAFKAHQ_CONFIGURATION: |
        kafkahq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "broker-1:9092,broker-2:9093"
              schema-registry:
                url: "http://schema-registry-1:8081"
              connect:
                url: "http://connect-1:8083"
    depends_on:
      - broker-1
    restart: always

  web:
    image: elkozmon/zoonavigator-web:0.5.1
    container_name: zoonavigator-web
    ports:
     - "28047:8010"
    environment:
      WEB_HTTP_PORT: 8010
      API_HOST: "api"
      API_PORT: 28048
    depends_on:
     - api
    restart: always
  api:
    image: elkozmon/zoonavigator-api:0.5.1
    container_name: zoonavigator-api
    environment:
      API_HTTP_PORT: 28048
    restart: always

  streamsets:
    image: trivadisbds/streamsets-kafka-nosql
    hostname: streamsets
    container_name: streamsets
    ports:
      - "28029:18630"
    restart: always

  nifi:
    image: apache/nifi
    hostname: nifi
    container_name: nifi
    ports:
      - "28054:8080"
    restart: always

  minio:
    hostname: minio
    image: minio/minio
    container_name: minio
    ports:
      - '28083:9000'
    environment:
      MINIO_ACCESS_KEY: V42FCGRVMK24JJ8DHUYG
      MINIO_SECRET_KEY: bKhWxVF3kQoLY9kFmt91l+tDrEoZjqnWXzY9Eza
    command: server /data
    restart: always
    
  zeppelin:
    image: trivadis/apache-zeppelin:0.8.2-hadoop2.7-spark2.4.4
    container_name: zeppelin
    hostname: zeppelin
    ports:
      - "28055:8080"
    environment:
      # AWS Credentials
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}

      ZEPPELIN_ADDR: "0.0.0.0"
      ZEPPELIN_PORT: "8080"
      ZEPPELIN_INTERPRETER_CONNECT_TIMEOUT: 120000
      SPARK_MASTER: "spark://spark-master:7077"

      # set spark-master for Zeppelin interpreter
      MASTER: "spark://spark-master:7077"
      SPARK_DRIVER_HOST: zeppelin
      SPARK_DRIVER_BINDADDRESS: "0.0.0.0"
      PYSPARK_PYTHON: "python3"
      SPARK_SUBMIT_OPTIONS: "--conf spark.driver.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4 --conf spark.executor.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4"
    volumes:
      - ./conf/zeppelin/shiro.ini:/opt/zeppelin/conf/shiro.ini
      - ./conf/zeppelin/interpreter-setting.json:/opt/zeppelin/interpreter/spark/interpreter-setting.json
      - ./data-transfer:/data-transfer
    restart: always

  jupyter:
    image: 'jupyter/all-spark-notebook:abdb27a6dfbb'
    container_name: jupyter
    hostname: jupyter
    ports:
      - '28060:8888'
    environment:
      JUPYTER_ENABLE_LAB: 'true'
      JUPYTER_TOKEN: abc123
      GRANT_SUDO: 'true'
      TINI_SUBREAPER: 'true'
    restart: always

  #  Container UI ===============================================
    
  portainer:
    image: portainer/portainer
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
#      - data_portainer:/data
#    environment:
#      - VIRTUAL_HOST=monitor.bioatlas.se
#      - VIRTUAL_PORT=9000
    ports:
      - 28071:9000   
    restart: always